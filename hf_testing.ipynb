{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "925c36aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/frank/gpu_mode/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1968\n",
    "\n",
    "import asyncio\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers.cache_utils import DynamicCache, StaticCache\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from shared import (\n",
    "    MessageChannel,\n",
    "    PrefillRequest,\n",
    "    PrefillResponse,\n",
    "    PrefillBatchRequest,\n",
    "    PrefillBatchResponse,\n",
    "    ResetRequest,\n",
    "    VerifyRequest,\n",
    "    VerifyResponse,\n",
    "    VerifyBatchRequest,\n",
    "    VerifyBatchResponse,\n",
    "    VerifyResponseItem,\n",
    ")\n",
    "\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87a42e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE_MODEL = os.environ.get(\"HF_BASE_MODEL\", \"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "# BASE_MODEL = os.environ.get(\"HF_BASE_MODEL\", \"meta-llama/Llama-3.2-1B-Instruct\")\n",
    "BASE_MODEL = os.environ.get(\"HF_BASE_MODEL\", \"meta-llama/Llama-3.1-8B\")\n",
    "TOP_K = int(os.environ.get(\"HF_TOP_K\", \"20\"))\n",
    "ATTN_IMPL_ENV = os.environ.get(\"HF_ATTN_IMPL\", \"\").strip()  # e.g., \"flash_attention_2\" if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72c8c50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('mps')\n",
    "DTYPE = torch.float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "998d5a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: c274c583-c99a-4e1a-b8d8-dcafa04377c1)')' thrown while requesting HEAD https://huggingface.co/meta-llama/Llama-3.1-8B/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.94it/s]\n"
     ]
    }
   ],
   "source": [
    "hf_token = os.environ.get(\"HF_TOKEN\", None)\n",
    "from_kwargs = {\n",
    "    \"dtype\": DTYPE,\n",
    "    \"device_map\": None,           # keep single process; move to one device below\n",
    "    \"low_cpu_mem_usage\": True,\n",
    "    \"token\": hf_token,\n",
    "}\n",
    "if ATTN_IMPL_ENV:\n",
    "    from_kwargs[\"attn_implementation\"] = ATTN_IMPL_ENV\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    **from_kwargs,\n",
    ").to(DEVICE) # type: ignore\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, use_fast=True, token=hf_token)\n",
    "\n",
    "PAD_ID = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else (\n",
    "    tokenizer.eos_token_id if tokenizer.eos_token_id is not None else 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4478cdd6",
   "metadata": {},
   "source": [
    "## Prefill Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c7cac08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "\n",
    "prompts_str = [\n",
    "    \"Explanation of speculative decoding in simple terms\",\n",
    "    \"This is a terse haiku about Apple MLX\",\n",
    "    \"Why is the sky blue\",\n",
    "]\n",
    "\n",
    "prompts: list[list[int]] = [tokenizer.encode(prompt) for prompt in prompts_str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b728b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mask_and_pos_ids(L: list[int]): # TODO: Should this be a list or a tensor?\n",
    "#     max_len = max(L)\n",
    "\n",
    "#     attention_mask = torch.zeros((len(L), max_len), dtype=torch.long, device=DEVICE)\n",
    "#     for i, l in enumerate(L):\n",
    "#         attention_mask[i, max_len - l:] = 1\n",
    "\n",
    "#     # position_ids / cache_position: 0..L_i-1 for non-pad tokens, 0 for pads\n",
    "#     # This works for both absolute and RoPE-style position handling.\n",
    "#     position_ids = (attention_mask.cumsum(dim=-1) - 1).clamp_min(0)\n",
    "#     position_ids = position_ids.masked_fill(attention_mask == 0, 0)\n",
    "\n",
    "#     return attention_mask, position_ids \n",
    "\n",
    "def mask_and_pos_ids(L: list[int]): # TODO: Should this be a list or a tensor?\n",
    "    max_len = max(L)\n",
    "\n",
    "    attention_mask = torch.zeros((len(L), max_len), dtype=torch.long, device=DEVICE)\n",
    "    for i, l in enumerate(L):\n",
    "        attention_mask[i, max_len - l:] = 1\n",
    "\n",
    "    # position_ids / cache_position: 0..L_i-1 for non-pad tokens, 0 for pads\n",
    "    # This works for both absolute and RoPE-style position handling.\n",
    "    position_ids = (attention_mask.cumsum(dim=-1) - 1).clamp_min(0)\n",
    "    position_ids = position_ids.masked_fill(attention_mask == 0, 0)\n",
    "\n",
    "    return attention_mask, position_ids \n",
    "\n",
    "@torch.inference_mode()\n",
    "def prefill(model: nn.Module, prompts: list[list[int]]):\n",
    "    max_len = max(len(x) for x in prompts)\n",
    "    padded = [[PAD_ID] * (max_len - len(prompt)) + prompt for prompt in prompts]  # is pad id 0 correct?\n",
    "    x = torch.tensor(padded, dtype=torch.long, device=DEVICE)\n",
    "\n",
    "    cache = DynamicCache(\n",
    "        config=model.config, \n",
    "    )\n",
    "\n",
    "    attention_mask, position_ids = mask_and_pos_ids([len(x) for x in prompts])\n",
    "\n",
    "    outputs = model(\n",
    "        input_ids=x, \n",
    "        # attention_mask=attention_mask,\n",
    "        past_key_values=cache, \n",
    "        use_cache=True,\n",
    "        # position_ids=position_ids,\n",
    "    )\n",
    "\n",
    "    return outputs.past_key_values\n",
    "\n",
    "cache = prefill(model, prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec609e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def zero_cache(cache: DynamicCache, lengths: list[int]):\n",
    "#     assert cache.layers[0].keys is not None and cache.layers[0].values is not None\n",
    "#     B = cache.layers[0].keys.shape[0]\n",
    "\n",
    "#     # Prepare destination cache\n",
    "#     dst = DynamicCache()\n",
    "\n",
    "#     for layer in range(len(cache)):\n",
    "#         K = cache.layers[layer].keys\n",
    "#         V = cache.layers[layer].values\n",
    "#         assert K is not None and V is not None\n",
    "\n",
    "#         _, H, S_old, D = K.shape\n",
    "\n",
    "#         K_new = K.new_zeros((B, H, S_old, D))\n",
    "#         V_new = V.new_zeros((B, H, S_old, D))\n",
    "\n",
    "#         # Copy per row\n",
    "#         for i in range(B):\n",
    "#             keep = int(S_keep[i].item())\n",
    "#             if keep == 0:\n",
    "#                 continue\n",
    "#             # surviving tokens are the first 'keep' positions (earliest..latest-rollback)\n",
    "#             K_src = K[i, :, :keep, :]\n",
    "#             V_src = V[i, :, :keep, :]\n",
    "\n",
    "#             # right-aligned → write to the right, pad on the left implicitly\n",
    "#             start = S_new - keep\n",
    "#             K_new[i, :, start:, :] = K_src\n",
    "#             V_new[i, :, start:, :] = V_src\n",
    "#             # print(K_new[i, 0, :, 0])\n",
    "\n",
    "#         # print(dst.layers[layer].keys[i, 0, :, 0])\n",
    "#         dst.update(K_new, V_new, layer)\n",
    "#         print(dst.layers[layer].keys[0, 0, :, 0])\n",
    "\n",
    "#     return dst\n",
    "\n",
    "# rollback_values = torch.tensor([3, 0, 1], dtype=torch.long, device=model.device)\n",
    "# # print(cache.layers[0].keys[:, 0, :, 0])\n",
    "# new_cache = rollback_dynamic_per_row_simple(cache, rollback_values)\n",
    "# print(new_cache.layers[0].keys[:, 0, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb2e9768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.5508,  0.7910, -4.6953, -0.3940, -2.1562,  3.0645,  7.5547,  3.3496,\n",
      "         -2.5117, -6.6289, -4.2461],\n",
      "        [ 0.4468,  1.0215, -3.5273, -5.5859, -2.6172,  3.6797,  9.8750,  3.3047,\n",
      "         -4.4180, -8.2578, -4.9453],\n",
      "        [ 5.5508,  0.7910, -4.6953, -5.8672, -1.6426, -0.2014,  7.8828,  2.9688,\n",
      "         -1.5879, -8.2578, -5.5938]], device='mps:0', dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "print(cache.layers[0].keys[:, 0, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0762af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "  Keys shape: torch.Size([3, 8, 11, 128])\n",
      "  Values shape: torch.Size([3, 8, 11, 128])\n",
      "Layer 1:\n",
      "  Keys shape: torch.Size([3, 8, 11, 128])\n",
      "  Values shape: torch.Size([3, 8, 11, 128])\n",
      "Layer 2:\n",
      "  Keys shape: torch.Size([3, 8, 11, 128])\n",
      "  Values shape: torch.Size([3, 8, 11, 128])\n",
      "Layer 3:\n",
      "  Keys shape: torch.Size([3, 8, 11, 128])\n",
      "  Values shape: torch.Size([3, 8, 11, 128])\n",
      "Layer 4:\n",
      "  Keys shape: torch.Size([3, 8, 11, 128])\n",
      "  Values shape: torch.Size([3, 8, 11, 128])\n",
      "Layer 5:\n",
      "  Keys shape: torch.Size([3, 8, 11, 128])\n",
      "  Values shape: torch.Size([3, 8, 11, 128])\n",
      "Layer 6:\n",
      "  Keys shape: torch.Size([3, 8, 11, 128])\n",
      "  Values shape: torch.Size([3, 8, 11, 128])\n",
      "Layer 7:\n",
      "  Keys shape: torch.Size([3, 8, 11, 128])\n",
      "  Values shape: torch.Size([3, 8, 11, 128])\n",
      "Layer 8:\n",
      "  Keys shape: torch.Size([3, 8, 11, 128])\n",
      "  Values shape: torch.Size([3, 8, 11, 128])\n",
      "Layer 9:\n",
      "  Keys shape: torch.Size([3, 8, 11, 128])\n",
      "  Values shape: torch.Size([3, 8, 11, 128])\n",
      "Layer 10:\n",
      "  Keys shape: torch.Size([3, 8, 11, 128])\n",
      "  Values shape: torch.Size([3, 8, 11, 128])\n",
      "Layer 11:\n",
      "  Keys shape: torch.Size([3, 8, 11, 128])\n",
      "  Values shape: torch.Size([3, 8, 11, 128])\n",
      "Layer 12:\n",
      "  Keys shape: torch.Size([3, 8, 11, 128])\n",
      "  Values shape: torch.Size([3, 8, 11, 128])\n",
      "Layer 13:\n",
      "  Keys shape: torch.Size([3, 8, 11, 128])\n",
      "  Values shape: torch.Size([3, 8, 11, 128])\n",
      "Layer 14:\n",
      "  Keys shape: torch.Size([3, 8, 11, 128])\n",
      "  Values shape: torch.Size([3, 8, 11, 128])\n",
      "Layer 15:\n",
      "  Keys shape: torch.Size([3, 8, 11, 128])\n",
      "  Values shape: torch.Size([3, 8, 11, 128])\n",
      "Layer 16:\n",
      "  Keys shape: torch.Size([3, 8, 11, 128])\n",
      "  Values shape: torch.Size([3, 8, 11, 128])\n",
      "Layer 17:\n",
      "  Keys shape: torch.Size([3, 8, 11, 128])\n",
      "  Values shape: torch.Size([3, 8, 11, 128])\n",
      "Layer 18:\n",
      "  Keys shape: torch.Size([3, 8, 11, 128])\n",
      "  Values shape: torch.Size([3, 8, 11, 128])\n",
      "Layer 19:\n",
      "  Keys shape: torch.Size([3, 8, 11, 128])\n",
      "  Values shape: torch.Size([3, 8, 11, 128])\n",
      "Layer 20:\n",
      "  Keys shape: torch.Size([3, 8, 11, 128])\n",
      "  Values shape: torch.Size([3, 8, 11, 128])\n",
      "Layer 21:\n",
      "  Keys shape: torch.Size([3, 8, 11, 128])\n",
      "  Values shape: torch.Size([3, 8, 11, 128])\n",
      "Layer 22:\n",
      "  Keys shape: torch.Size([3, 8, 11, 128])\n",
      "  Values shape: torch.Size([3, 8, 11, 128])\n",
      "Layer 23:\n",
      "  Keys shape: torch.Size([3, 8, 11, 128])\n",
      "  Values shape: torch.Size([3, 8, 11, 128])\n",
      "Layer 24:\n",
      "  Keys shape: torch.Size([3, 8, 11, 128])\n",
      "  Values shape: torch.Size([3, 8, 11, 128])\n",
      "Layer 25:\n",
      "  Keys shape: torch.Size([3, 8, 11, 128])\n",
      "  Values shape: torch.Size([3, 8, 11, 128])\n",
      "Layer 26:\n",
      "  Keys shape: torch.Size([3, 8, 11, 128])\n",
      "  Values shape: torch.Size([3, 8, 11, 128])\n",
      "Layer 27:\n",
      "  Keys shape: torch.Size([3, 8, 11, 128])\n",
      "  Values shape: torch.Size([3, 8, 11, 128])\n",
      "Layer 28:\n",
      "  Keys shape: torch.Size([3, 8, 11, 128])\n",
      "  Values shape: torch.Size([3, 8, 11, 128])\n",
      "Layer 29:\n",
      "  Keys shape: torch.Size([3, 8, 11, 128])\n",
      "  Values shape: torch.Size([3, 8, 11, 128])\n",
      "Layer 30:\n",
      "  Keys shape: torch.Size([3, 8, 11, 128])\n",
      "  Values shape: torch.Size([3, 8, 11, 128])\n",
      "Layer 31:\n",
      "  Keys shape: torch.Size([3, 8, 11, 128])\n",
      "  Values shape: torch.Size([3, 8, 11, 128])\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(cache.layers):\n",
    "    print(f\"Layer {i}:\")\n",
    "    print(f\"  Keys shape: {layer.keys.shape}\")\n",
    "    print(f\"  Values shape: {layer.values.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a146fac4",
   "metadata": {},
   "source": [
    "## Pure Decode (Just A Sanity Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a41a74b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 12])\n",
      "tensor([[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:00<00:04,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 13])\n",
      "tensor([[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]], device='mps:0')\n",
      "torch.Size([3, 14])\n",
      "tensor([[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:00<00:02,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 15])\n",
      "tensor([[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='mps:0')\n",
      "torch.Size([3, 16])\n",
      "tensor([[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:01<00:02,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 17])\n",
      "tensor([[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='mps:0')\n",
      "torch.Size([3, 18])\n",
      "tensor([[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:01<00:01,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 19])\n",
      "tensor([[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='mps:0')\n",
      "torch.Size([3, 20])\n",
      "tensor([[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [00:01<00:01,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 21])\n",
      "tensor([[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='mps:0')\n",
      "torch.Size([3, 22])\n",
      "tensor([[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [00:01<00:01,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 23])\n",
      "tensor([[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='mps:0')\n",
      "torch.Size([3, 24])\n",
      "tensor([[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [00:02<00:00,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 25])\n",
      "tensor([[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1]], device='mps:0')\n",
      "torch.Size([3, 26])\n",
      "tensor([[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1],\n",
      "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [00:02<00:00,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 27])\n",
      "tensor([[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]], device='mps:0')\n",
      "torch.Size([3, 28])\n",
      "tensor([[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1]], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [00:02<00:00,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 29])\n",
      "tensor([[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1]], device='mps:0')\n",
      "torch.Size([3, 30])\n",
      "tensor([[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:03<00:00,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 31])\n",
      "tensor([[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1]], device='mps:0')\n",
      "<|begin_of_text|>Explanation of speculative decoding in simple terms: Speculative decoding is a technique used in computer architecture to optimize the execution of instructions. It involves\n",
      "<|begin_of_text|>This is a terse haiku about Apple MLX: a machine learning framework for iOS and macOS. It’s a powerful tool for developers to create machine\n",
      "<|begin_of_text|>Why is the sky blue: The sky blue?\n",
      "The sky appears blue due to a phenomenon called Rayleigh scattering. This occurs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# @torch.inference_mode()\n",
    "# def generate_step(model: nn.Module, cache: StaticCache, tokens: list[int], lengths: torch.LongTensor):\n",
    "#     x = torch.tensor(tokens, dtype=torch.long, device=DEVICE).view(-1, 1)\n",
    "\n",
    "#     B = lengths.size(0)\n",
    "#     S_prev = cache.layers[0].keys.shape[2]   # current cache time dim (same for all rows)\n",
    "#     S_tot  = S_prev + 1                      # we add one token\n",
    "\n",
    "#     # Mask: keep only (real prompt + generated so far) + the new token, right-aligned\n",
    "#     attn_mask = torch.zeros((B, S_tot), dtype=torch.long, device=DEVICE)\n",
    "#     for i, l in enumerate(lengths.tolist()):\n",
    "#         attn_mask[i, S_prev - l - 1:] = 1   # existing real tokens\n",
    "#         attn_mask[i, -1] = 1            # the new token itself\n",
    "\n",
    "#     # print(attn_mask)\n",
    "\n",
    "#     # Rope positions (per row) for the NEW token are exactly L\n",
    "#     pos_ids = lengths.view(B, 1)\n",
    "\n",
    "#     # Where to write in the cache (index along the time dimension) for this step\n",
    "#     # cache_pos = torch.full((B, 1), S_prev, dtype=torch.long, device=DEVICE)\n",
    "    \n",
    "#     outputs = model(\n",
    "#         x, \n",
    "#         use_cache=True, \n",
    "#         past_key_values=cache,\n",
    "#         attention_mask=attn_mask,\n",
    "#         position_ids=pos_ids,      # keep rope continuity\n",
    "#         # cache_position=cache_pos,  # write K/V at the next slot\n",
    "#     )\n",
    "\n",
    "#     tokens = outputs.logits.argmax(axis=-1).tolist()\n",
    "#     lengths = lengths + 1\n",
    "#     return tokens, lengths\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def generate_step(\n",
    "    model: nn.Module,\n",
    "    cache: DynamicCache,\n",
    "    tokens: list[list[int]],\n",
    "    lengths: torch.LongTensor,\n",
    "):\n",
    "    x = torch.tensor(tokens, dtype=torch.long, device=DEVICE).view(-1, 1)\n",
    "\n",
    "    B = lengths.size(0)\n",
    "    S_prev = cache.layers[0].keys.shape[2]\n",
    "\n",
    "    # Use int64 (not bool) on MPS; build past + current token mask\n",
    "    attn_mask = torch.zeros((B, S_prev + 1), dtype=torch.long, device=DEVICE)\n",
    "\n",
    "    starts = (S_prev - lengths).clamp_min(0)                # (B,)\n",
    "    idx = torch.arange(S_prev, device=DEVICE)[None, :]      # (1, S_prev)\n",
    "    attn_mask[:, :-1] = (idx >= starts[:, None]).to(torch.long)\n",
    "    attn_mask[:, -1] = 1\n",
    "\n",
    "    print(attn_mask.shape)\n",
    "    print(attn_mask)\n",
    "\n",
    "    pos_ids = lengths.view(B, 1)  # new token's RoPE position (0..L_i)\n",
    "\n",
    "    out = model(\n",
    "        input_ids=x,\n",
    "        past_key_values=cache,\n",
    "        use_cache=True,\n",
    "        attention_mask=attn_mask,  # int mask\n",
    "        position_ids=pos_ids,\n",
    "    )\n",
    "\n",
    "    next_tok = out.logits[:, -1].argmax(dim=-1).tolist()\n",
    "    lengths = lengths + 1\n",
    "    return [[t] for t in next_tok], lengths\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "suffix_text = ':'\n",
    "tokens = [[x] for x in tokenizer.encode(suffix_text)[1:]] * 3\n",
    "full_tokens = prompts\n",
    "\n",
    "lengths = torch.tensor([len(x) for x in prompts], dtype=torch.long, device=model.device)\n",
    "\n",
    "for _ in tqdm(range(20)):\n",
    "    full_tokens: list[list[int]] = [x + y for x, y in zip(full_tokens, tokens)]\n",
    "\n",
    "    tokens, lengths = generate_step(model, cache, tokens, lengths)\n",
    "\n",
    "for i in range(3):\n",
    "    print(tokenizer.decode(full_tokens[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211ac483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e54bed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.5508,  5.5508,  5.5508,  0.4468,  1.1914, -3.6875, -7.4219, -2.4609,\n",
      "          3.2773,  6.6562,  3.4648, -0.9922, -3.0820, -2.2852,  0.6128,  2.9492,\n",
      "          2.5723, -0.1682, -2.7539, -2.8086, -0.2803,  2.5039,  2.9883,  0.7236,\n",
      "         -2.2070, -3.1074, -1.1514,  1.8633,  3.1660,  1.5566, -1.4824],\n",
      "        [ 0.4468,  1.0215, -3.5273, -5.5859, -2.6172,  3.6797,  9.8750,  3.3047,\n",
      "         -4.4180, -8.2578, -4.9453,  0.4590,  5.4766,  5.6875, -1.4619, -6.6797,\n",
      "         -4.9961,  0.1621,  4.3750,  7.0586,  0.8062, -5.2578, -5.4805, -1.4014,\n",
      "          4.8320,  7.1250,  2.4062, -4.3164, -5.2734, -3.2305,  3.5684],\n",
      "        [ 5.5508,  5.5508,  5.5508,  5.5508,  5.5508,  0.4468,  1.3496, -3.5273,\n",
      "         -4.6562, -3.6094,  4.7266,  3.7832,  1.9541, -1.0459, -3.0820, -2.2852,\n",
      "          0.6128,  2.9492,  2.5723, -0.1682, -2.7539, -2.8086, -0.2803,  2.5039,\n",
      "          2.9883,  0.7236, -2.2070, -3.1074, -1.1514,  1.8633,  3.1660]],\n",
      "       device='mps:0', dtype=torch.float16)\n",
      "tensor([[ 5.5508,  5.5508,  5.5508,  0.4468,  1.1914, -3.6875, -7.4219, -2.4609,\n",
      "          3.2773,  6.6562,  3.4648, -0.9922, -3.0820, -2.2852,  0.6128,  2.9492,\n",
      "          2.5723, -0.1682, -2.7539, -2.8086, -0.2803,  2.5039,  2.9883,  0.7236,\n",
      "         -2.2070, -3.1074, -1.1514,  1.8633,  3.1660],\n",
      "        [ 0.4468,  1.0215, -3.5273, -5.5859, -2.6172,  3.6797,  9.8750,  3.3047,\n",
      "         -4.4180, -8.2578, -4.9453,  0.4590,  5.4766,  5.6875, -1.4619, -6.6797,\n",
      "         -4.9961,  0.1621,  4.3750,  7.0586,  0.8062, -5.2578, -5.4805, -1.4014,\n",
      "          4.8320,  7.1250,  2.4062, -4.3164, -5.2734],\n",
      "        [ 5.5508,  5.5508,  5.5508,  5.5508,  5.5508,  0.4468,  1.3496, -3.5273,\n",
      "         -4.6562, -3.6094,  4.7266,  3.7832,  1.9541, -1.0459, -3.0820, -2.2852,\n",
      "          0.6128,  2.9492,  2.5723, -0.1682, -2.7539, -2.8086, -0.2803,  2.5039,\n",
      "          2.9883,  0.7236, -2.2070, -3.1074, -1.1514]], device='mps:0',\n",
      "       dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "print(cache.layers[0].keys[:, 0, :, 0])\n",
    "cache.crop(-2)\n",
    "print(cache.layers[0].keys[:, 0, :, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58562114",
   "metadata": {},
   "source": [
    "## Experimental Verify Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0fea74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[719, 420, 374, 264, 2216, 5505, 1296, 13], [719, 420, 374, 264, 2216, 5505, 1296, 13], [719, 420, 374, 264, 2216, 5505, 1296, 13]]\n",
      "torch.Size([3, 8, 37, 128])\n"
     ]
    }
   ],
   "source": [
    "@torch.inference_mode()\n",
    "def verify(model: nn.Module, cache: DynamicCache, tokens: list[list[int]], draft_logits: np.array):\n",
    "    assert all([len(x) == len(tokens[0]) for x in tokens])\n",
    "    print(tokens)\n",
    "    x = torch.tensor(tokens, dtype=torch.long, device=DEVICE)\n",
    "\n",
    "    outputs = model(\n",
    "        x, \n",
    "        use_cache=True, \n",
    "        past_key_values=cache\n",
    "    )\n",
    "\n",
    "    print(cache.layers[0].keys.shape)\n",
    "\n",
    "\n",
    "suffix_text = ' but this is a really useful test.'\n",
    "suffix_tokens = tokenizer.encode(suffix_text)[1:]\n",
    "\n",
    "verify(model, cache, [suffix_tokens for _ in range(3)], None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33875371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000,  0.0000,  0.0000,  5.5508,  5.5508,  5.5508,  0.4468,  1.1914,\n",
      "        -3.6875, -7.4219, -2.4609,  3.2773,  6.6562,  3.4648, -0.9922, -3.0820,\n",
      "        -2.2852,  0.6128,  2.9492,  2.5723, -0.1682, -2.7539, -2.8086, -0.2803,\n",
      "         2.5039,  2.9883,  0.7236, -2.2070, -3.1074, -1.1514,  1.8633,  3.1660,\n",
      "        -3.1875,  2.7129,  5.3828,  3.5391, -2.0801], device='mps:0',\n",
      "       dtype=torch.float16)\n",
      "tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,         nan,         nan,\n",
      "                nan, -3.2978e-03,  4.0664e+00,  1.1885e+00, -5.6953e+00,\n",
      "        -4.9805e+00, -1.0137e+00,  6.3086e+00,  4.4688e+00,  2.4062e+00,\n",
      "        -3.2754e+00, -4.4336e+00, -2.0840e+00,  2.2461e+00,  4.5742e+00,\n",
      "         2.6562e+00, -1.6953e+00, -4.4375e+00, -3.0879e+00,  1.0508e+00,\n",
      "         4.1836e+00,  3.4336e+00, -4.9414e-01, -3.9199e+00, -3.6934e+00,\n",
      "        -8.9844e-02,  3.5410e+00, -5.7617e+00, -2.2109e+00,  3.4258e+00,\n",
      "         3.7461e+00,  6.2744e-01], device='mps:0', dtype=torch.float16)\n",
      "tensor([0., 0., 0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='mps:0', dtype=torch.float16)\n",
      "tensor([0., 0., 0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='mps:0', dtype=torch.float16)\n",
      "tensor([0., 0., 0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='mps:0', dtype=torch.float16)\n",
      "tensor([0., 0., 0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='mps:0', dtype=torch.float16)\n",
      "tensor([0., 0., 0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='mps:0', dtype=torch.float16)\n",
      "tensor([0., 0., 0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='mps:0', dtype=torch.float16)\n",
      "tensor([0., 0., 0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='mps:0', dtype=torch.float16)\n",
      "tensor([0., 0., 0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='mps:0', dtype=torch.float16)\n",
      "tensor([0., 0., 0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='mps:0', dtype=torch.float16)\n",
      "tensor([0., 0., 0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='mps:0', dtype=torch.float16)\n",
      "tensor([0., 0., 0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='mps:0', dtype=torch.float16)\n",
      "tensor([0., 0., 0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='mps:0', dtype=torch.float16)\n",
      "tensor([0., 0., 0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='mps:0', dtype=torch.float16)\n",
      "tensor([0., 0., 0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='mps:0', dtype=torch.float16)\n",
      "tensor([0., 0., 0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='mps:0', dtype=torch.float16)\n",
      "tensor([0., 0., 0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='mps:0', dtype=torch.float16)\n",
      "tensor([0., 0., 0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='mps:0', dtype=torch.float16)\n",
      "tensor([0., 0., 0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='mps:0', dtype=torch.float16)\n",
      "tensor([0., 0., 0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='mps:0', dtype=torch.float16)\n",
      "tensor([0., 0., 0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='mps:0', dtype=torch.float16)\n",
      "tensor([0., 0., 0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='mps:0', dtype=torch.float16)\n",
      "tensor([0., 0., 0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='mps:0', dtype=torch.float16)\n",
      "tensor([0., 0., 0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='mps:0', dtype=torch.float16)\n",
      "tensor([0., 0., 0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='mps:0', dtype=torch.float16)\n",
      "tensor([0., 0., 0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='mps:0', dtype=torch.float16)\n",
      "tensor([0., 0., 0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='mps:0', dtype=torch.float16)\n",
      "tensor([0., 0., 0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='mps:0', dtype=torch.float16)\n",
      "tensor([0., 0., 0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='mps:0', dtype=torch.float16)\n",
      "tensor([0., 0., 0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='mps:0', dtype=torch.float16)\n",
      "tensor([0., 0., 0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "       device='mps:0', dtype=torch.float16)\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  5.5508,  5.5508,  5.5508,  0.4468,  1.1914,\n",
      "         -3.6875, -7.4219, -2.4609,  3.2773,  6.6562,  3.4648, -0.9922, -3.0820,\n",
      "         -2.2852,  0.6128,  2.9492,  2.5723, -0.1682, -2.7539, -2.8086, -0.2803,\n",
      "          2.5039,  2.9883,  0.7236, -2.2070, -3.1074, -1.1514,  1.8633,  3.1660,\n",
      "         -3.1875,  2.7129,  5.3828,  3.5391, -2.0801],\n",
      "        [ 0.4468,  1.0215, -3.5273, -5.5859, -2.6172,  3.6797,  9.8750,  3.3047,\n",
      "         -4.4180, -8.2578, -4.9453,  0.4590,  5.4766,  5.6875, -1.4619, -6.6797,\n",
      "         -4.9961,  0.1621,  4.3750,  7.0586,  0.8062, -5.2578, -5.4805, -1.4014,\n",
      "          4.8320,  7.1250,  2.4062, -4.3164, -5.2734, -3.1875,  2.7129,  5.3828,\n",
      "          3.5391, -2.0801, -6.3438, -4.8164, -0.2000],\n",
      "        [ 0.0000,  5.5508,  5.5508,  5.5508,  5.5508,  5.5508,  0.4468,  1.3496,\n",
      "         -3.5273, -4.6562, -3.6094,  4.7266,  3.7832,  1.9541, -1.0459, -3.0820,\n",
      "         -2.2852,  0.6128,  2.9492,  2.5723, -0.1682, -2.7539, -2.8086, -0.2803,\n",
      "          2.5039,  2.9883,  0.7236, -2.2070, -3.1074, -1.1514, -3.1875,  2.7129,\n",
      "          5.3828,  3.5391, -2.0801, -6.3438, -4.8164]], device='mps:0',\n",
      "       dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "def rollback_dynamic_per_row_simple(cache: DynamicCache, r: torch.LongTensor):\n",
    "    \"\"\"\n",
    "    Roll back r[i] tokens for each batch row i in a DynamicCache.\n",
    "    Produce a new DynamicCache with time dim S_new = max_i (S_old - r[i]).\n",
    "    \"\"\"\n",
    "    assert cache.layers[0].keys is not None and cache.layers[0].values is not None\n",
    "    assert (r >= 0).all().item()\n",
    "    B = cache.layers[0].keys.shape[0]\n",
    "    device = cache.layers[0].keys.device\n",
    "    dtype = cache.layers[0].keys.dtype\n",
    "\n",
    "    # Prepare destination cache\n",
    "    dst = DynamicCache()\n",
    "\n",
    "    for layer in range(len(cache)):\n",
    "        K = cache.layers[layer].keys\n",
    "        V = cache.layers[layer].values\n",
    "        assert K is not None and V is not None\n",
    "\n",
    "        _, H, S_old, D = K.shape\n",
    "\n",
    "        # Per-row keep lengths\n",
    "        S_keep = S_old - r  # shape (B,)\n",
    "        S_new = int(S_keep.max().item())\n",
    "\n",
    "        K_new = K.new_zeros((B, H, S_new, D))\n",
    "        V_new = V.new_zeros((B, H, S_new, D))\n",
    "\n",
    "        # Copy per row\n",
    "        for i in range(B):\n",
    "            keep = int(S_keep[i].item())\n",
    "            if keep == 0:\n",
    "                continue\n",
    "            # surviving tokens are the first 'keep' positions (earliest..latest-rollback)\n",
    "            K_src = K[i, :, :keep, :]\n",
    "            V_src = V[i, :, :keep, :]\n",
    "\n",
    "            # right-aligned → write to the right, pad on the left implicitly\n",
    "            start = S_new - keep\n",
    "            K_new[i, :, start:, :] = K_src\n",
    "            V_new[i, :, start:, :] = V_src\n",
    "            # print(K_new[i, 0, :, 0])\n",
    "\n",
    "        # print(dst.layers[layer].keys[i, 0, :, 0])\n",
    "        dst.update(K_new, V_new, layer)\n",
    "        print(dst.layers[layer].keys[0, 0, :, 0])\n",
    "\n",
    "    return dst\n",
    "\n",
    "rollback_values = torch.tensor([3, 0, 1], dtype=torch.long, device=model.device)\n",
    "# print(cache.layers[0].keys[:, 0, :, 0])\n",
    "new_cache = rollback_dynamic_per_row_simple(cache, rollback_values)\n",
    "print(new_cache.layers[0].keys[:, 0, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfda1995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rollback_dynamic_per_row(cache: DynamicCache, r: torch.LongTensor):\n",
    "#     \"\"\"\n",
    "#     Roll back r[i] tokens for each batch row i in a DynamicCache.\n",
    "#     Returns a *new* DynamicCache with time dim equal to max(L_i - r_i).\n",
    "#     \"\"\"\n",
    "#     assert cache.layers[0].keys is not None\n",
    "#     B = cache.layers[0].keys.shape[0]\n",
    "#     device = cache.layers[0].keys.device\n",
    "#     uniq = torch.unique(r)\n",
    "\n",
    "#     # Build empty destination (we'll fill layer by layer)\n",
    "#     dst = DynamicCache()\n",
    "#     for layer in range(len(cache)):\n",
    "#         K = cache.layers[layer].keys\n",
    "#         V = cache.layers[layer].keys\n",
    "#         assert K is not None\n",
    "#         assert V is not None\n",
    "\n",
    "#         B, H, S_old, D = K.shape\n",
    "#         # Compute new per-row lengths after rollback\n",
    "#         L_after = torch.full((B,), S_old, dtype=torch.long, device=device) - r\n",
    "#         S_new = int(L_after.max().item())\n",
    "\n",
    "#         K_new = K.new_zeros(B, H, S_new, D)\n",
    "#         V_new = V.new_zeros(B, H, S_new, D)\n",
    "\n",
    "#         # For each rollback bucket, crop and scatter back\n",
    "#         for rv in uniq.tolist():\n",
    "#             idx = (r == rv).nonzero(as_tuple=False).squeeze(-1)\n",
    "#             if idx.numel() == 0: \n",
    "#                 continue\n",
    "#             # Select sub-batch, crop rv tokens from the right\n",
    "#             K_sub = K.index_select(0, idx)\n",
    "#             V_sub = V.index_select(0, idx)\n",
    "\n",
    "#             # physical crop for this bucket\n",
    "#             S_keep = S_old - rv\n",
    "#             K_sub = K_sub[..., :S_keep, :]\n",
    "#             V_sub = V_sub[..., :S_keep, :]\n",
    "\n",
    "#             # place back into dst; zero-filling beyond S_keep keeps them \"rolled back\"\n",
    "#             K_new.index_copy_(0, idx, torch.nn.functional.pad(K_sub, (0,0,0,0,0, S_new - S_keep)))\n",
    "#             V_new.index_copy_(0, idx, torch.nn.functional.pad(V_sub, (0,0,0,0,0, S_new - S_keep)))\n",
    "\n",
    "#         dst.update(K_new, V_new, layer)\n",
    "\n",
    "#     return dst\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
